{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from nltk.translate import bleu\n",
    "from keras.utils import plot_model\n",
    "from strsimpy.cosine import Cosine\n",
    "from strsimpy.jaccard import Jaccard\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from strsimpy.levenshtein import Levenshtein\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURATION\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "NUM_SAMPLES = 50000\n",
    "LATENT_DIMENSIONS = 32\n",
    "\n",
    "DATA_PATH = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 50000\n",
      "Number of unique input tokens: 37\n",
      "Number of unique output tokens: 39\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 24\n"
     ]
    }
   ],
   "source": [
    "accepted_characters = sorted(list(\" abcdefghijklmnopqrstuvwxyz1234567890\"))\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "## DATA PREPROCESSING\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(NUM_SAMPLES, len(lines) - 1)]:\n",
    "    input_text, _, _ = line.split('\\t')\n",
    "    input_text = input_text.lower()\n",
    "    input_text = \"\".join(char for char in input_text if char in accepted_characters)\n",
    "    target_text = '\\t' + input_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)    \n",
    "\n",
    "num_encoder_tokens = len(accepted_characters)\n",
    "num_decoder_tokens = num_encoder_tokens + 2\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(accepted_characters)])\n",
    "target_token_index = dict([(char, i + 2) for i, char in enumerate(accepted_characters)])\n",
    "target_token_index['\\t'] = 0\n",
    "target_token_index['\\n'] = 1\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype = 'float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):        \n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, 37)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 32), (None,  8960        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 39)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        lstm_3[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1056        lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 32), ( 9216        input_6[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 39)     1287        lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 21,575\n",
      "Trainable params: 21,575\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AUTOENCODER MODEL DEFINITION\n",
    "    \n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(LATENT_DIMENSIONS, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "state_h_dense = Dense(LATENT_DIMENSIONS, activation = \"sigmoid\")\n",
    "state_c_dense = Dense(LATENT_DIMENSIONS, activation = \"sigmoid\")\n",
    "state_h = state_h_dense(state_h)\n",
    "state_c = state_c_dense(state_c)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape = (None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(LATENT_DIMENSIONS, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 2.0916 - accuracy: 0.4308 - val_loss: 2.4402 - val_accuracy: 0.3160\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 15s 373us/step - loss: 1.6128 - accuracy: 0.5381 - val_loss: 2.0246 - val_accuracy: 0.4102\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 15s 377us/step - loss: 1.4370 - accuracy: 0.5763 - val_loss: 1.8840 - val_accuracy: 0.4405\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 15s 376us/step - loss: 1.3443 - accuracy: 0.5992 - val_loss: 1.8047 - val_accuracy: 0.4581\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 1.2754 - accuracy: 0.6150 - val_loss: 1.7287 - val_accuracy: 0.4739\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 15s 376us/step - loss: 1.2172 - accuracy: 0.6302 - val_loss: 1.6665 - val_accuracy: 0.4949\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 15s 377us/step - loss: 1.1673 - accuracy: 0.6440 - val_loss: 1.6615 - val_accuracy: 0.4981\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 1.1256 - accuracy: 0.6562 - val_loss: 1.5604 - val_accuracy: 0.5236\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 1.0869 - accuracy: 0.6676 - val_loss: 1.5488 - val_accuracy: 0.5261\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 1.0519 - accuracy: 0.6778 - val_loss: 1.4929 - val_accuracy: 0.5428\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 1.0236 - accuracy: 0.6865 - val_loss: 1.4613 - val_accuracy: 0.5541\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 15s 381us/step - loss: 0.9991 - accuracy: 0.6939 - val_loss: 1.4287 - val_accuracy: 0.5657\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 15s 381us/step - loss: 0.9785 - accuracy: 0.7002 - val_loss: 1.4429 - val_accuracy: 0.5640\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.9596 - accuracy: 0.7057 - val_loss: 1.3743 - val_accuracy: 0.5791\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.9423 - accuracy: 0.7111 - val_loss: 1.3862 - val_accuracy: 0.5785\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.9270 - accuracy: 0.7156 - val_loss: 1.3633 - val_accuracy: 0.5814\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.9126 - accuracy: 0.7200 - val_loss: 1.3386 - val_accuracy: 0.5923\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.8995 - accuracy: 0.7237 - val_loss: 1.4364 - val_accuracy: 0.5743\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.8873 - accuracy: 0.7273 - val_loss: 1.3474 - val_accuracy: 0.5903\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.8749 - accuracy: 0.7309 - val_loss: 1.2903 - val_accuracy: 0.6035\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.8642 - accuracy: 0.7341 - val_loss: 1.3166 - val_accuracy: 0.6010\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.8538 - accuracy: 0.7368 - val_loss: 1.3395 - val_accuracy: 0.6001\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.8432 - accuracy: 0.7403 - val_loss: 1.2856 - val_accuracy: 0.6094\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.8339 - accuracy: 0.7426 - val_loss: 1.2873 - val_accuracy: 0.6095\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.8244 - accuracy: 0.7457 - val_loss: 1.2386 - val_accuracy: 0.6197\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.8160 - accuracy: 0.7478 - val_loss: 1.3190 - val_accuracy: 0.5985\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.8078 - accuracy: 0.7502 - val_loss: 1.2264 - val_accuracy: 0.6241\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.7999 - accuracy: 0.7526 - val_loss: 1.3076 - val_accuracy: 0.6032\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7931 - accuracy: 0.7545 - val_loss: 1.2630 - val_accuracy: 0.6154\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7855 - accuracy: 0.7565 - val_loss: 1.2256 - val_accuracy: 0.6264\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7780 - accuracy: 0.7591 - val_loss: 1.3434 - val_accuracy: 0.6103\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7710 - accuracy: 0.7611 - val_loss: 1.1929 - val_accuracy: 0.6352\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 15s 381us/step - loss: 0.7648 - accuracy: 0.7627 - val_loss: 1.2549 - val_accuracy: 0.6165\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.7569 - accuracy: 0.7652 - val_loss: 1.1989 - val_accuracy: 0.6340\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7506 - accuracy: 0.7673 - val_loss: 1.1760 - val_accuracy: 0.6396\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.7439 - accuracy: 0.7688 - val_loss: 1.1871 - val_accuracy: 0.6357\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.7380 - accuracy: 0.7706 - val_loss: 1.1311 - val_accuracy: 0.6532\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.7311 - accuracy: 0.7726 - val_loss: 1.1451 - val_accuracy: 0.6487\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 15s 379us/step - loss: 0.7248 - accuracy: 0.7746 - val_loss: 1.1701 - val_accuracy: 0.6423\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 15s 381us/step - loss: 0.7198 - accuracy: 0.7756 - val_loss: 1.1272 - val_accuracy: 0.6536\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 15s 381us/step - loss: 0.7129 - accuracy: 0.7779 - val_loss: 1.1982 - val_accuracy: 0.6337\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 16s 402us/step - loss: 0.7084 - accuracy: 0.7792 - val_loss: 1.1213 - val_accuracy: 0.6562\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 0.7032 - accuracy: 0.7808 - val_loss: 1.1091 - val_accuracy: 0.6585\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.6980 - accuracy: 0.7825 - val_loss: 1.0955 - val_accuracy: 0.6629\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 18s 456us/step - loss: 0.6933 - accuracy: 0.7839 - val_loss: 1.1143 - val_accuracy: 0.6580\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 0.6882 - accuracy: 0.7856 - val_loss: 1.1621 - val_accuracy: 0.6467\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 0.6849 - accuracy: 0.7863 - val_loss: 1.1172 - val_accuracy: 0.6590\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 20s 495us/step - loss: 0.6792 - accuracy: 0.7880 - val_loss: 1.1416 - val_accuracy: 0.6540\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 20s 501us/step - loss: 0.6747 - accuracy: 0.7894 - val_loss: 1.0636 - val_accuracy: 0.6726\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 21s 516us/step - loss: 0.6709 - accuracy: 0.7906 - val_loss: 1.1200 - val_accuracy: 0.6568\n"
     ]
    }
   ],
   "source": [
    "## TRAINING (Done once per configuration)\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split = 0.2)\n",
    "model.save_weights('./model_weights/quantized/s2s_' + str(EPOCHS) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_SAMPLES) + \"_\" + str(LATENT_DIMENSIONS) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING PRETRAINED WEIGHTS\n",
    "\n",
    "model.load_weights('./model_weights/quantized/s2s_' + str(EPOCHS) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_SAMPLES) + \"_\" + str(LATENT_DIMENSIONS) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INFERENCE MODEL\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape = (LATENT_DIMENSIONS,))\n",
    "decoder_state_input_c = Input(shape = (LATENT_DIMENSIONS,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x):\n",
    "    return (x > 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, quant = False):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    if quant:\n",
    "        states_value[0] = quantize(states_value[0])\n",
    "        states_value[1] = quantize(states_value[1])\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: when will you be back\n",
      "Decoded sentence: whe mes you be for me\n",
      "\n",
      "Quantized Decoded sentence: whes we be benybery done\n",
      "\n",
      "-\n",
      "Input sentence: when will you be free\n",
      "Decoded sentence: whe mes you be for me\n",
      "\n",
      "Quantized Decoded sentence: whes we be benybery done\n",
      "\n",
      "-\n",
      "Input sentence: when will you be free\n",
      "Decoded sentence: whe mes you be for me\n",
      "\n",
      "Quantized Decoded sentence: whes we be benybery done\n",
      "\n",
      "-\n",
      "Input sentence: where are my children\n",
      "Decoded sentence: where your sie a love\n",
      "\n",
      "Quantized Decoded sentence: wes weres be bery tere fo\n",
      "-\n",
      "Input sentence: where are my scissors\n",
      "Decoded sentence: where are all tom mes\n",
      "\n",
      "Quantized Decoded sentence: wes meres bery fely homes\n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are are ar furt\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are are ar furt\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are are ar furt\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are my trousers\n",
      "Decoded sentence: we lose wonfor car me\n",
      "\n",
      "Quantized Decoded sentence: were well be car a gook\n",
      "\n",
      "-\n",
      "Input sentence: where are my trousers\n",
      "Decoded sentence: we lose wonfor car me\n",
      "\n",
      "Quantized Decoded sentence: were well be car a gook\n",
      "\n",
      "-\n",
      "Input sentence: where are our friends\n",
      "Decoded sentence: where you sell baree\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are the glasses\n",
      "Decoded sentence: where are the car med\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are the glasses\n",
      "Decoded sentence: where are the car med\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are the showers\n",
      "Decoded sentence: where are the mad you\n",
      "\n",
      "Quantized Decoded sentence: wed keeksed tem lonke it\n",
      "\n",
      "-\n",
      "Input sentence: where are the toilets\n",
      "Decoded sentence: where are the tompand\n",
      "\n",
      "Quantized Decoded sentence: were welk to seed mare\n",
      "\n",
      "-\n",
      "Input sentence: where are the victims\n",
      "Decoded sentence: where are to sees med\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: where you like to bay\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you staying\n",
      "Decoded sentence: where you like to you\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you staying\n",
      "Decoded sentence: where you like to you\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where are you working\n",
      "Decoded sentence: we come seel all men\n",
      "\n",
      "Quantized Decoded sentence: were well be car a gook\n",
      "\n",
      "-\n",
      "Input sentence: where are your gloves\n",
      "Decoded sentence: we lose be be lovesed\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are your people\n",
      "Decoded sentence: where your in freater\n",
      "\n",
      "Quantized Decoded sentence: wes mere were relly well \n",
      "-\n",
      "Input sentence: where are your things\n",
      "Decoded sentence: where you like to me\n",
      "\n",
      "Quantized Decoded sentence: we feel your wat hime\n",
      "\n",
      "-\n",
      "Input sentence: where are your things\n",
      "Decoded sentence: where you like to me\n",
      "\n",
      "Quantized Decoded sentence: we feel your wat hime\n",
      "\n",
      "-\n",
      "Input sentence: where can i reach you\n",
      "Decoded sentence: where are it look her\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where can i reach you\n",
      "Decoded sentence: where are it look her\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where did you grow up\n",
      "Decoded sentence: we kead is bery here\n",
      "\n",
      "Quantized Decoded sentence: wered tell we reed male\n",
      "\n",
      "-\n",
      "Input sentence: where did you grow up\n",
      "Decoded sentence: we kead is bery here\n",
      "\n",
      "Quantized Decoded sentence: wered tell we reed male\n",
      "\n",
      "-\n",
      "Input sentence: where did you guys go\n",
      "Decoded sentence: we kead is ber saned\n",
      "\n",
      "Quantized Decoded sentence: wered tell we reed male\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where not andas wand\n",
      "\n",
      "Quantized Decoded sentence: weres do were an wasten\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where not andas wand\n",
      "\n",
      "Quantized Decoded sentence: weres do were an wasten\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where not andas wand\n",
      "\n",
      "Quantized Decoded sentence: weres do were an wasten\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where not andas wand\n",
      "\n",
      "Quantized Decoded sentence: weres do were an wasten\n",
      "\n",
      "-\n",
      "Input sentence: where do you all live\n",
      "Decoded sentence: where too for sar ofe\n",
      "\n",
      "Quantized Decoded sentence: whesed toodbrebry dry wan\n",
      "-\n",
      "Input sentence: where do you live now\n",
      "Decoded sentence: where you to rely war\n",
      "\n",
      "Quantized Decoded sentence: whesed toodbrebry dry wan\n",
      "-\n",
      "Input sentence: where do you work now\n",
      "Decoded sentence: we were is be reable\n",
      "\n",
      "Quantized Decoded sentence: wered tell we reed male\n",
      "\n",
      "-\n",
      "Input sentence: where do you work now\n",
      "Decoded sentence: we were is be reable\n",
      "\n",
      "Quantized Decoded sentence: wered tell we reed male\n",
      "\n",
      "-\n",
      "Input sentence: where exactly are you\n",
      "Decoded sentence: where yours a so fur\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where exactly are you\n",
      "Decoded sentence: where yours a so fur\n",
      "\n",
      "Quantized Decoded sentence: were wel seel andor hom\n",
      "\n",
      "-\n",
      "Input sentence: where is tom sleeping\n",
      "Decoded sentence: where is to freat med\n",
      "\n",
      "Quantized Decoded sentence: wheret tht me prees head\n",
      "\n",
      "-\n",
      "Input sentence: where is my newspaper\n",
      "Decoded sentence: where a mad flater in\n",
      "\n",
      "Quantized Decoded sentence: were wel were all a wark\n",
      "\n",
      "-\n",
      "Input sentence: where is my newspaper\n",
      "Decoded sentence: where a mad flater in\n",
      "\n",
      "Quantized Decoded sentence: were wel were all a wark\n",
      "\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: where is to tead sore\n",
      "\n",
      "Quantized Decoded sentence: whree thot that of you\n",
      "\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: where is to tead sore\n",
      "\n",
      "Quantized Decoded sentence: whree thot that of you\n",
      "\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: where is to tead sore\n",
      "\n",
      "Quantized Decoded sentence: whree thot that of you\n",
      "\n",
      "-\n",
      "Input sentence: where is the bus stop\n",
      "Decoded sentence: where is to son here\n",
      "\n",
      "Quantized Decoded sentence: whree got that to baly\n",
      "\n",
      "-\n",
      "Input sentence: where is the elevator\n",
      "Decoded sentence: where is to for a gook\n",
      "\n",
      "Quantized Decoded sentence: werst we toms he shess me\n",
      "-\n",
      "Input sentence: where is the elevator\n",
      "Decoded sentence: where is to for a gook\n",
      "\n",
      "Quantized Decoded sentence: werst we toms he shess me\n",
      "-\n",
      "Input sentence: where is the evidence\n",
      "Decoded sentence: where is to for a gook\n",
      "\n",
      "Quantized Decoded sentence: werst we toms he shess me\n",
      "-\n",
      "Input sentence: where is your luggage\n",
      "Decoded sentence: wher is nover of my me\n",
      "\n",
      "Quantized Decoded sentence: whes need you brery crets\n",
      "-\n",
      "Input sentence: where is your luggage\n",
      "Decoded sentence: wher is nover of my me\n",
      "\n",
      "Quantized Decoded sentence: whes need you brery crets\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where sate can sone\n",
      "\n",
      "Quantized Decoded sentence: were wes compe see hoolt\n",
      "\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where sate can sone\n",
      "\n",
      "Quantized Decoded sentence: were wes compe see hoolt\n",
      "\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where sate can sone\n",
      "\n",
      "Quantized Decoded sentence: were wes compe see hoolt\n",
      "\n",
      "-\n",
      "Input sentence: where was your father\n",
      "Decoded sentence: where not sul are you\n",
      "\n",
      "Quantized Decoded sentence: wered thereser see here\n",
      "\n",
      "-\n",
      "Input sentence: where was your father\n",
      "Decoded sentence: where not sul are you\n",
      "\n",
      "Quantized Decoded sentence: wered thereser see here\n",
      "\n",
      "-\n",
      "Input sentence: where were all of you\n",
      "Decoded sentence: where mery is broning\n",
      "\n",
      "Quantized Decoded sentence: were wel were all a wark\n",
      "\n",
      "-\n",
      "Input sentence: where were all of you\n",
      "Decoded sentence: where mery is broning\n",
      "\n",
      "Quantized Decoded sentence: were wel were all a wark\n",
      "\n",
      "-\n",
      "Input sentence: where were the others\n",
      "Decoded sentence: we kees we see her in\n",
      "\n",
      "Quantized Decoded sentence: wed keekes there angand\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: where were the police\n",
      "Decoded sentence: wel we come some hear\n",
      "\n",
      "Quantized Decoded sentence: wed keeked the learn you\n",
      "\n",
      "-\n",
      "Input sentence: where were they going\n",
      "Decoded sentence: we kees wean caly her\n",
      "\n",
      "Quantized Decoded sentence: wed keekes there angand\n",
      "\n",
      "-\n",
      "Input sentence: where were they going\n",
      "Decoded sentence: we kees wean caly her\n",
      "\n",
      "Quantized Decoded sentence: wed keekes there angand\n",
      "\n",
      "-\n",
      "Input sentence: where were you hiding\n",
      "Decoded sentence: we kees and createre\n",
      "\n",
      "Quantized Decoded sentence: wed keessed me read men\n",
      "\n",
      "-\n",
      "Input sentence: where were you hiding\n",
      "Decoded sentence: we kees and createre\n",
      "\n",
      "Quantized Decoded sentence: wed keessed me read men\n",
      "\n",
      "-\n",
      "Input sentence: wherere toms things\n",
      "Decoded sentence: wel were hand hime\n",
      "\n",
      "Quantized Decoded sentence: wed kekswes whing this\n",
      "\n",
      "-\n",
      "Input sentence: wheres everyone else\n",
      "Decoded sentence: where free for fored\n",
      "\n",
      "Quantized Decoded sentence: wes keepked your reme me\n",
      "\n",
      "-\n",
      "Input sentence: wheres everyone else\n",
      "Decoded sentence: where free for fored\n",
      "\n",
      "Quantized Decoded sentence: wes keepked your reme me\n",
      "\n",
      "-\n",
      "Input sentence: wheres my microphone\n",
      "Decoded sentence: where sem my fall you\n",
      "\n",
      "Quantized Decoded sentence: were wel were all a wark\n",
      "\n",
      "-\n",
      "Input sentence: wheres my other shoe\n",
      "Decoded sentence: where see to seed you\n",
      "\n",
      "Quantized Decoded sentence: wered wels of seed food\n",
      "\n",
      "-\n",
      "Input sentence: wheres the red cross\n",
      "Decoded sentence: wheres the bread me\n",
      "\n",
      "Quantized Decoded sentence: weres wentoner my weased\n",
      "\n",
      "-\n",
      "Input sentence: wheres the red cross\n",
      "Decoded sentence: wheres the bread me\n",
      "\n",
      "Quantized Decoded sentence: weres wentoner my weased\n",
      "\n",
      "-\n",
      "Input sentence: wheres the newspaper\n",
      "Decoded sentence: wheres the my mes mes\n",
      "\n",
      "Quantized Decoded sentence: weres wentoner my weased\n",
      "\n",
      "-\n",
      "Input sentence: wheres your daughter\n",
      "Decoded sentence: where beas you spees\n",
      "\n",
      "Quantized Decoded sentence: were seere bar aw yough\n",
      "\n",
      "-\n",
      "Input sentence: wheres your daughter\n",
      "Decoded sentence: where beas you spees\n",
      "\n",
      "Quantized Decoded sentence: were seere bar aw yough\n",
      "\n",
      "-\n",
      "Input sentence: wheres your passport\n",
      "Decoded sentence: where sund lear ford\n",
      "\n",
      "Quantized Decoded sentence: were seere bar aw yough\n",
      "\n",
      "-\n",
      "Input sentence: wheres your suitcase\n",
      "Decoded sentence: where sand colpenged\n",
      "\n",
      "Quantized Decoded sentence: were seere bar aw yough\n",
      "\n",
      "-\n",
      "Input sentence: which is your luggage\n",
      "Decoded sentence: whis as you for spead\n",
      "\n",
      "Quantized Decoded sentence: wh hithe leake real her\n",
      "\n",
      "-\n",
      "Input sentence: which is your luggage\n",
      "Decoded sentence: whis as you for spead\n",
      "\n",
      "Quantized Decoded sentence: wh hithe leake real her\n",
      "\n",
      "-\n",
      "Input sentence: which team are you on\n",
      "Decoded sentence: whats ase a beateroo\n",
      "\n",
      "Quantized Decoded sentence: whw is to tain your fay\n",
      "\n",
      "-\n",
      "Input sentence: who am i talking with\n",
      "Decoded sentence: what a now cang hime\n",
      "\n",
      "Quantized Decoded sentence: wh thit wis reed me is ou\n",
      "-\n",
      "Input sentence: who are you afraid of\n",
      "Decoded sentence: whay oud your sachert\n",
      "\n",
      "Quantized Decoded sentence: get you be yerellass me\n",
      "\n",
      "-\n",
      "Input sentence: who are you to decide\n",
      "Decoded sentence: whay do you cant me it\n",
      "\n",
      "Quantized Decoded sentence: wh tont dont leake away h\n",
      "-\n",
      "Input sentence: who are you to decide\n",
      "Decoded sentence: whay do you cant me it\n",
      "\n",
      "Quantized Decoded sentence: wh tont dont leake away h\n",
      "-\n",
      "Input sentence: who asked tom to sing\n",
      "Decoded sentence: what reake to to sors\n",
      "\n",
      "Quantized Decoded sentence: wht need had the chanted\n",
      "\n",
      "-\n",
      "Input sentence: who asked you to sing\n",
      "Decoded sentence: what reake to my here\n",
      "\n",
      "Quantized Decoded sentence: hw thented no keed a chow\n",
      "-\n",
      "Input sentence: who ate all the fruit\n",
      "Decoded sentence: what you saud a came\n",
      "\n",
      "Quantized Decoded sentence: wht this beed a pead men\n",
      "\n",
      "-\n",
      "Input sentence: who broke this window\n",
      "Decoded sentence: we ineed rach a wathe\n",
      "\n",
      "Quantized Decoded sentence: we be benter with it its\n",
      "\n",
      "-\n",
      "Input sentence: who built the snowman\n",
      "Decoded sentence: who beat sun aspish me\n",
      "\n",
      "Quantized Decoded sentence: we thit you like the the \n",
      "-\n",
      "Input sentence: who cares about facts\n",
      "Decoded sentence: whay look tel see you\n",
      "\n",
      "Quantized Decoded sentence: he were bryoned me hame\n",
      "\n",
      "-\n",
      "Input sentence: who closed the window\n",
      "Decoded sentence: whe areed has a doone\n",
      "\n",
      "Quantized Decoded sentence: we we llove what thised\n",
      "\n",
      "-\n",
      "Input sentence: who crashed the party\n",
      "Decoded sentence: whe arech ant a door\n",
      "\n",
      "Quantized Decoded sentence: we whinell wat thit thate\n",
      "-\n",
      "Input sentence: who did you come with\n",
      "Decoded sentence: who tome were a saug\n",
      "\n",
      "Quantized Decoded sentence: whtt wh be be was wasted\n",
      "\n",
      "-\n",
      "Input sentence: who did you talk with\n",
      "Decoded sentence: who tome was my chem\n",
      "\n",
      "Quantized Decoded sentence: whtt wh be be was wasted\n",
      "\n",
      "-\n",
      "Input sentence: who do you think i am\n",
      "Decoded sentence: who tom wand a goode\n",
      "\n",
      "Quantized Decoded sentence: wh to on to to so looke\n",
      "\n",
      "-\n",
      "Input sentence: who else is out there\n",
      "Decoded sentence: whe are a was a houre\n",
      "\n",
      "Quantized Decoded sentence: whe bey ase how thit thas\n",
      "BLEU Score =  0.9797\n",
      "Cosine Score =  0.2063\n",
      "Jaccard Score =  0.4819\n",
      "Levenshtein Score =  16.65\n"
     ]
    }
   ],
   "source": [
    "## VALIDATION TESTING\n",
    "\n",
    "start = int(NUM_SAMPLES * 0.9) + 100\n",
    "samples = 100\n",
    "\n",
    "bleu_val = 0\n",
    "cosine_val = 0\n",
    "jaccard_val = 0\n",
    "levenshtein_val = 0\n",
    "\n",
    "cosine = Cosine(1)\n",
    "jaccard = Jaccard(1)\n",
    "levenshtein = Levenshtein()\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "for seq_index in range(start, start + samples):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    decoded_sentence_quant = decode_sequence(input_seq, quant = True)\n",
    "    \n",
    "    cosine_val += cosine.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    jaccard_val += jaccard.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    levenshtein_val += levenshtein.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    bleu_val += bleu([input_texts[seq_index].split()], decoded_sentence_quant.split(), smoothing_function = smoothie)    \n",
    "    \n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('Quantized Decoded sentence:', decoded_sentence_quant)\n",
    "    \n",
    "print(\"BLEU Score = \", round(1. - (bleu_val / samples), 4))\n",
    "print(\"Cosine Score = \", round(cosine_val / samples, 4))\n",
    "print(\"Jaccard Score = \", round(jaccard_val / samples, 4))\n",
    "print(\"Levenshtein Score = \", round(levenshtein_val / samples, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
