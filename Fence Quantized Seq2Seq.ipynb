{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from nltk.translate import bleu\n",
    "from keras.utils import plot_model\n",
    "from strsimpy.cosine import Cosine\n",
    "from strsimpy.jaccard import Jaccard\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from strsimpy.levenshtein import Levenshtein\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURATION\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "NUM_SAMPLES = 50000\n",
    "LATENT_DIMENSIONS = 32\n",
    "\n",
    "DATA_PATH = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 50000\n",
      "Number of unique input tokens: 37\n",
      "Number of unique output tokens: 39\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 24\n"
     ]
    }
   ],
   "source": [
    "accepted_characters = sorted(list(\" abcdefghijklmnopqrstuvwxyz1234567890\"))\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "## DATA PREPROCESSING\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(NUM_SAMPLES, len(lines) - 1)]:\n",
    "    input_text, _, _ = line.split('\\t')\n",
    "    input_text = input_text.lower()\n",
    "    input_text = \"\".join(char for char in input_text if char in accepted_characters)\n",
    "    target_text = '\\t' + input_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)    \n",
    "\n",
    "num_encoder_tokens = len(accepted_characters)\n",
    "num_decoder_tokens = num_encoder_tokens + 2\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(accepted_characters)])\n",
    "target_token_index = dict([(char, i + 2) for i, char in enumerate(accepted_characters)])\n",
    "target_token_index['\\t'] = 0\n",
    "target_token_index['\\n'] = 1\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype = 'float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):        \n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fence_loss(codes):\n",
    "    return K.mean(K.minimum(codes , 1. - codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 37)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 32), (None,  8960        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 39)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           1056        lstm_1[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 32), ( 9216        input_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 39)     1287        lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 21,575\n",
      "Trainable params: 21,575\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## AUTOENCODER MODEL DEFINITION\n",
    "    \n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(LATENT_DIMENSIONS, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "state_h_dense = Dense(LATENT_DIMENSIONS, activation = \"sigmoid\")\n",
    "state_c_dense = Dense(LATENT_DIMENSIONS, activation = \"sigmoid\")\n",
    "state_h = state_h_dense(state_h)\n",
    "state_c = state_c_dense(state_c)\n",
    "fence_state_h = fence_loss(state_h)\n",
    "fence_state_c = fence_loss(state_c)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape = (None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(LATENT_DIMENSIONS, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.add_loss(fence_state_h * 0.001)\n",
    "model.add_loss(fence_state_c * 0.001)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr0/home/vparimi/anaconda3/envs/gradai/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 2.0829 - accuracy: 0.4373 - val_loss: 2.3757 - val_accuracy: 0.3328\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 1.6031 - accuracy: 0.5378 - val_loss: 1.9633 - val_accuracy: 0.4226\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 1.4345 - accuracy: 0.5737 - val_loss: 1.9042 - val_accuracy: 0.4300\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 1.3539 - accuracy: 0.5968 - val_loss: 1.8171 - val_accuracy: 0.4540\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 1.2839 - accuracy: 0.6167 - val_loss: 1.7040 - val_accuracy: 0.4858\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 1.2297 - accuracy: 0.6326 - val_loss: 1.6363 - val_accuracy: 0.5059\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 1.1868 - accuracy: 0.6454 - val_loss: 1.6311 - val_accuracy: 0.5057\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 1.1498 - accuracy: 0.6565 - val_loss: 1.6220 - val_accuracy: 0.5105\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 1.1139 - accuracy: 0.6657 - val_loss: 1.5225 - val_accuracy: 0.5405\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 1.0830 - accuracy: 0.6742 - val_loss: 1.5096 - val_accuracy: 0.5432\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 1.0571 - accuracy: 0.6810 - val_loss: 1.4801 - val_accuracy: 0.5539\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 1.0350 - accuracy: 0.6873 - val_loss: 1.4571 - val_accuracy: 0.5602\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 1.0149 - accuracy: 0.6932 - val_loss: 1.5370 - val_accuracy: 0.5464\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.9969 - accuracy: 0.6984 - val_loss: 1.4787 - val_accuracy: 0.5566\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.9792 - accuracy: 0.7029 - val_loss: 1.4021 - val_accuracy: 0.5731\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.9632 - accuracy: 0.7073 - val_loss: 1.3704 - val_accuracy: 0.5863\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.9472 - accuracy: 0.7115 - val_loss: 1.3661 - val_accuracy: 0.5832\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.9322 - accuracy: 0.7160 - val_loss: 1.3552 - val_accuracy: 0.5853\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.9185 - accuracy: 0.7192 - val_loss: 1.3769 - val_accuracy: 0.5810\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.9063 - accuracy: 0.7231 - val_loss: 1.3152 - val_accuracy: 0.6019\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.8953 - accuracy: 0.7262 - val_loss: 1.3370 - val_accuracy: 0.6000\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.8855 - accuracy: 0.7287 - val_loss: 1.3224 - val_accuracy: 0.5952\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.8758 - accuracy: 0.7320 - val_loss: 1.2881 - val_accuracy: 0.6061\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.8673 - accuracy: 0.7344 - val_loss: 1.2926 - val_accuracy: 0.6065\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.8590 - accuracy: 0.7366 - val_loss: 1.2757 - val_accuracy: 0.6096\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.8509 - accuracy: 0.7392 - val_loss: 1.2618 - val_accuracy: 0.6150\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.8439 - accuracy: 0.7413 - val_loss: 1.2795 - val_accuracy: 0.6147\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.8372 - accuracy: 0.7433 - val_loss: 1.3044 - val_accuracy: 0.6108\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.8309 - accuracy: 0.7452 - val_loss: 1.2786 - val_accuracy: 0.6094\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.8245 - accuracy: 0.7470 - val_loss: 1.2139 - val_accuracy: 0.6298\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.8185 - accuracy: 0.7494 - val_loss: 1.2483 - val_accuracy: 0.6184\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.8126 - accuracy: 0.7507 - val_loss: 1.3139 - val_accuracy: 0.5987\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.8076 - accuracy: 0.7521 - val_loss: 1.2291 - val_accuracy: 0.6267\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.8019 - accuracy: 0.7533 - val_loss: 1.2200 - val_accuracy: 0.6299\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.7969 - accuracy: 0.7552 - val_loss: 1.1886 - val_accuracy: 0.6377\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.7919 - accuracy: 0.7569 - val_loss: 1.2740 - val_accuracy: 0.6217\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.7875 - accuracy: 0.7581 - val_loss: 1.1917 - val_accuracy: 0.6364\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.7825 - accuracy: 0.7599 - val_loss: 1.2958 - val_accuracy: 0.6133\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.7777 - accuracy: 0.7614 - val_loss: 1.2087 - val_accuracy: 0.6308\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.7726 - accuracy: 0.7628 - val_loss: 1.2783 - val_accuracy: 0.6186\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 0.7683 - accuracy: 0.7640 - val_loss: 1.2787 - val_accuracy: 0.6240\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 17s 434us/step - loss: 0.7637 - accuracy: 0.7657 - val_loss: 1.1885 - val_accuracy: 0.6416\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 20s 500us/step - loss: 0.7599 - accuracy: 0.7664 - val_loss: 1.2374 - val_accuracy: 0.6245\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.7549 - accuracy: 0.7676 - val_loss: 1.1968 - val_accuracy: 0.6355\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 20s 501us/step - loss: 0.7511 - accuracy: 0.7689 - val_loss: 1.2217 - val_accuracy: 0.6322\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 21s 531us/step - loss: 0.7465 - accuracy: 0.7703 - val_loss: 1.1971 - val_accuracy: 0.6404\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 21s 535us/step - loss: 0.7423 - accuracy: 0.7711 - val_loss: 1.1449 - val_accuracy: 0.6504\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 21s 534us/step - loss: 0.7380 - accuracy: 0.7727 - val_loss: 1.1718 - val_accuracy: 0.6442\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 22s 551us/step - loss: 0.7341 - accuracy: 0.7737 - val_loss: 1.1557 - val_accuracy: 0.6466\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 22s 540us/step - loss: 0.7303 - accuracy: 0.7752 - val_loss: 1.2291 - val_accuracy: 0.6307\n"
     ]
    }
   ],
   "source": [
    "## TRAINING (Done once per configuration)\n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split = 0.2)\n",
    "model.save_weights('./model_weights/fence_quantized/s2s_' + str(EPOCHS) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_SAMPLES) + \"_\" + str(LATENT_DIMENSIONS) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING PRETRAINED WEIGHTS\n",
    "\n",
    "model.load_weights('./model_weights/fence_quantized/s2s_' + str(EPOCHS) + \"_\" + str(BATCH_SIZE) + \"_\" + str(NUM_SAMPLES) + \"_\" + str(LATENT_DIMENSIONS) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INFERENCE MODEL\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape = (LATENT_DIMENSIONS,))\n",
    "decoder_state_input_c = Input(shape = (LATENT_DIMENSIONS,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x):\n",
    "    return (x > 0.5).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, quant = False):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    if quant:\n",
    "        states_value[0] = quantize(states_value[0])\n",
    "        states_value[1] = quantize(states_value[1])\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: when will you be back\n",
      "Decoded sentence: whe dont you go tome\n",
      "\n",
      "Quantized Decoded sentence: whw younke kneve tom\n",
      "\n",
      "-\n",
      "Input sentence: when will you be free\n",
      "Decoded sentence: whe dont you realled\n",
      "\n",
      "Quantized Decoded sentence: whw younk yeve we her\n",
      "\n",
      "-\n",
      "Input sentence: when will you be free\n",
      "Decoded sentence: whe dont you realled\n",
      "\n",
      "Quantized Decoded sentence: whw younk yeve we her\n",
      "\n",
      "-\n",
      "Input sentence: where are my children\n",
      "Decoded sentence: where ane be dead tom\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where are my scissors\n",
      "Decoded sentence: where see mestrain me\n",
      "\n",
      "Quantized Decoded sentence: wherd yourre deed tom\n",
      "\n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are bee read me\n",
      "\n",
      "Quantized Decoded sentence: whered me youred fore\n",
      "\n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are bee read me\n",
      "\n",
      "Quantized Decoded sentence: whered me youred fore\n",
      "\n",
      "-\n",
      "Input sentence: where are my slippers\n",
      "Decoded sentence: where are bee read me\n",
      "\n",
      "Quantized Decoded sentence: whered me youred fore\n",
      "\n",
      "-\n",
      "Input sentence: where are my trousers\n",
      "Decoded sentence: where aned you stared\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are my trousers\n",
      "Decoded sentence: where aned you stared\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are our friends\n",
      "Decoded sentence: why are fing a goors\n",
      "\n",
      "Quantized Decoded sentence: wher drey feed the me\n",
      "\n",
      "-\n",
      "Input sentence: where are the glasses\n",
      "Decoded sentence: where wer store to me\n",
      "\n",
      "Quantized Decoded sentence: wherd yourre be ding\n",
      "\n",
      "-\n",
      "Input sentence: where are the glasses\n",
      "Decoded sentence: where wer store to me\n",
      "\n",
      "Quantized Decoded sentence: wherd yourre be ding\n",
      "\n",
      "-\n",
      "Input sentence: where are the showers\n",
      "Decoded sentence: wheres the me the bat\n",
      "\n",
      "Quantized Decoded sentence: whers mere a proke a pain\n",
      "-\n",
      "Input sentence: where are the toilets\n",
      "Decoded sentence: why dont did with tom\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where are the victims\n",
      "Decoded sentence: why dont did want tom\n",
      "\n",
      "Quantized Decoded sentence: whad you his you like han\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you heading\n",
      "Decoded sentence: why dont dread the go\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you staying\n",
      "Decoded sentence: why dont dread to may\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you staying\n",
      "Decoded sentence: why dont dread to may\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are you working\n",
      "Decoded sentence: why dont dread to mer\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where are your gloves\n",
      "Decoded sentence: why dod need to deng\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where are your people\n",
      "Decoded sentence: why dont deed my here\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where are your things\n",
      "Decoded sentence: why dont dred the mar\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where are your things\n",
      "Decoded sentence: why dont dred the mar\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where can i reach you\n",
      "Decoded sentence: why dont ant stare it\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where can i reach you\n",
      "Decoded sentence: why dont ant stare it\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where did you grow up\n",
      "Decoded sentence: where did you go her\n",
      "\n",
      "Quantized Decoded sentence: wherd you didned tome\n",
      "\n",
      "-\n",
      "Input sentence: where did you grow up\n",
      "Decoded sentence: where did you go her\n",
      "\n",
      "Quantized Decoded sentence: wherd you didned tome\n",
      "\n",
      "-\n",
      "Input sentence: where did you guys go\n",
      "Decoded sentence: where do yourred mery\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where do your go dowy\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where do your go dowy\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where do your go dowy\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where did you hide it\n",
      "Decoded sentence: where do your go dowy\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where do you all live\n",
      "Decoded sentence: why dont feel stay me\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where do you live now\n",
      "Decoded sentence: where in youre funnt\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where do you work now\n",
      "Decoded sentence: where ins youre fain\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where do you work now\n",
      "Decoded sentence: where ins youre fain\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where exactly are you\n",
      "Decoded sentence: why dont feel shomer\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where exactly are you\n",
      "Decoded sentence: why dont feel shomer\n",
      "\n",
      "Quantized Decoded sentence: wheres youreded youred\n",
      "\n",
      "-\n",
      "Input sentence: where is tom sleeping\n",
      "Decoded sentence: why dont stare to mer\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where is my newspaper\n",
      "Decoded sentence: why dont dad no sing\n",
      "\n",
      "Quantized Decoded sentence: whad you his you like han\n",
      "-\n",
      "Input sentence: where is my newspaper\n",
      "Decoded sentence: why dont dad no sing\n",
      "\n",
      "Quantized Decoded sentence: whad you his you like han\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: why dont shot starery\n",
      "\n",
      "Quantized Decoded sentence: wheres merathing a dig th\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: why dont shot starery\n",
      "\n",
      "Quantized Decoded sentence: wheres merathing a dig th\n",
      "-\n",
      "Input sentence: where is the bathroom\n",
      "Decoded sentence: why dont shot starery\n",
      "\n",
      "Quantized Decoded sentence: wheres merathing a dig th\n",
      "-\n",
      "Input sentence: where is the bus stop\n",
      "Decoded sentence: why dont shot stared\n",
      "\n",
      "Quantized Decoded sentence: wheres merathing a dig th\n",
      "-\n",
      "Input sentence: where is the elevator\n",
      "Decoded sentence: why dont stay all here\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where is the elevator\n",
      "Decoded sentence: why dont stay all here\n",
      "\n",
      "Quantized Decoded sentence: whed mo were amed you sta\n",
      "-\n",
      "Input sentence: where is the evidence\n",
      "Decoded sentence: why do is you stanie\n",
      "\n",
      "Quantized Decoded sentence: whed w is youre me the th\n",
      "-\n",
      "Input sentence: where is your luggage\n",
      "Decoded sentence: why dont dread to for\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where is your luggage\n",
      "Decoded sentence: why dont dread to for\n",
      "\n",
      "Quantized Decoded sentence: whers youredy be bick\n",
      "\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where hers good to me\n",
      "\n",
      "Quantized Decoded sentence: whwe nower me me be me ma\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where hers good to me\n",
      "\n",
      "Quantized Decoded sentence: whwe nower me me be me ma\n",
      "-\n",
      "Input sentence: where should i put it\n",
      "Decoded sentence: where hers good to me\n",
      "\n",
      "Quantized Decoded sentence: whwe nower me me be me ma\n",
      "-\n",
      "Input sentence: where was your father\n",
      "Decoded sentence: wher me a geed the go\n",
      "\n",
      "Quantized Decoded sentence: whwe njod a fear you hant\n",
      "-\n",
      "Input sentence: where was your father\n",
      "Decoded sentence: wher me a geed the go\n",
      "\n",
      "Quantized Decoded sentence: whwe njod a fear you hant\n",
      "-\n",
      "Input sentence: where were all of you\n",
      "Decoded sentence: where ane your goore\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where were all of you\n",
      "Decoded sentence: where ane your goore\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where were the others\n",
      "Decoded sentence: where do me tom is it\n",
      "\n",
      "Quantized Decoded sentence: wherdy did you still\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: where were the police\n",
      "Decoded sentence: where do you wand tom\n",
      "\n",
      "Quantized Decoded sentence: wherd youre fing a up\n",
      "\n",
      "-\n",
      "Input sentence: where were they going\n",
      "Decoded sentence: where were tere be in\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where were they going\n",
      "Decoded sentence: where were tere be in\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where were you hiding\n",
      "Decoded sentence: where were you stuned\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: where were you hiding\n",
      "Decoded sentence: where were you stuned\n",
      "\n",
      "Quantized Decoded sentence: whers youre very look\n",
      "\n",
      "-\n",
      "Input sentence: wherere toms things\n",
      "Decoded sentence: whered to like hard\n",
      "\n",
      "Quantized Decoded sentence: wherd youre know thes\n",
      "\n",
      "-\n",
      "Input sentence: wheres everyone else\n",
      "Decoded sentence: where begenter bich\n",
      "\n",
      "Quantized Decoded sentence: wherd you didnt fine\n",
      "\n",
      "-\n",
      "Input sentence: wheres everyone else\n",
      "Decoded sentence: where begenter bich\n",
      "\n",
      "Quantized Decoded sentence: wherd you didnt fine\n",
      "\n",
      "-\n",
      "Input sentence: wheres my microphone\n",
      "Decoded sentence: wheres my reat for me\n",
      "\n",
      "Quantized Decoded sentence: wherd youre know thes\n",
      "\n",
      "-\n",
      "Input sentence: wheres my other shoe\n",
      "Decoded sentence: wheres you sare them\n",
      "\n",
      "Quantized Decoded sentence: wherd youre know thes\n",
      "\n",
      "-\n",
      "Input sentence: wheres the red cross\n",
      "Decoded sentence: wheres the dee heres\n",
      "\n",
      "Quantized Decoded sentence: whewed you like here\n",
      "\n",
      "-\n",
      "Input sentence: wheres the red cross\n",
      "Decoded sentence: wheres the dee heres\n",
      "\n",
      "Quantized Decoded sentence: whewed you like here\n",
      "\n",
      "-\n",
      "Input sentence: wheres the newspaper\n",
      "Decoded sentence: wheres a good to tom\n",
      "\n",
      "Quantized Decoded sentence: whewed a me beeran all si\n",
      "-\n",
      "Input sentence: wheres your daughter\n",
      "Decoded sentence: wheres your dring ar\n",
      "\n",
      "Quantized Decoded sentence: wherd youre deed that\n",
      "\n",
      "-\n",
      "Input sentence: wheres your daughter\n",
      "Decoded sentence: wheres your dring ar\n",
      "\n",
      "Quantized Decoded sentence: wherd youre deed that\n",
      "\n",
      "-\n",
      "Input sentence: wheres your passport\n",
      "Decoded sentence: whered the fear yours\n",
      "\n",
      "Quantized Decoded sentence: wherd youre know thes\n",
      "\n",
      "-\n",
      "Input sentence: wheres your suitcase\n",
      "Decoded sentence: whered the feel shome\n",
      "\n",
      "Quantized Decoded sentence: wherd youre know thes\n",
      "\n",
      "-\n",
      "Input sentence: which is your luggage\n",
      "Decoded sentence: who is alled you sture\n",
      "\n",
      "Quantized Decoded sentence: thhats gured you sure min\n",
      "-\n",
      "Input sentence: which is your luggage\n",
      "Decoded sentence: who is alled you sture\n",
      "\n",
      "Quantized Decoded sentence: thhats gured you sure min\n",
      "-\n",
      "Input sentence: which team are you on\n",
      "Decoded sentence: who is not my an bich\n",
      "\n",
      "Quantized Decoded sentence: what a hat be singed\n",
      "\n",
      "-\n",
      "Input sentence: who am i talking with\n",
      "Decoded sentence: who have the compared\n",
      "\n",
      "Quantized Decoded sentence: what has a come bust\n",
      "\n",
      "-\n",
      "Input sentence: who are you afraid of\n",
      "Decoded sentence: who sook your my mused\n",
      "\n",
      "Quantized Decoded sentence: what a boughe your free h\n",
      "-\n",
      "Input sentence: who are you to decide\n",
      "Decoded sentence: who is youred you here\n",
      "\n",
      "Quantized Decoded sentence: what a boughe your free h\n",
      "-\n",
      "Input sentence: who are you to decide\n",
      "Decoded sentence: who is youred you here\n",
      "\n",
      "Quantized Decoded sentence: what a boughe your free h\n",
      "-\n",
      "Input sentence: who asked tom to sing\n",
      "Decoded sentence: what ane tome be bear\n",
      "\n",
      "Quantized Decoded sentence: what a bury alled my a go\n",
      "-\n",
      "Input sentence: who asked you to sing\n",
      "Decoded sentence: what are you for your\n",
      "\n",
      "Quantized Decoded sentence: what dey very freelond\n",
      "\n",
      "-\n",
      "Input sentence: who ate all the fruit\n",
      "Decoded sentence: who is on your singen\n",
      "\n",
      "Quantized Decoded sentence: what a boughe your free h\n",
      "-\n",
      "Input sentence: who broke this window\n",
      "Decoded sentence: who beg is my all say\n",
      "\n",
      "Quantized Decoded sentence: whw youlled you go al\n",
      "\n",
      "-\n",
      "Input sentence: who built the snowman\n",
      "Decoded sentence: why hould to be canery\n",
      "\n",
      "Quantized Decoded sentence: whw me you wand you stay \n",
      "-\n",
      "Input sentence: who cares about facts\n",
      "Decoded sentence: who is me my read ane\n",
      "\n",
      "Quantized Decoded sentence: who wall me my ready the \n",
      "-\n",
      "Input sentence: who closed the window\n",
      "Decoded sentence: who in in my real all\n",
      "\n",
      "Quantized Decoded sentence: whw is not your your go d\n",
      "-\n",
      "Input sentence: who crashed the party\n",
      "Decoded sentence: who she in my the sald\n",
      "\n",
      "Quantized Decoded sentence: what has a broughed\n",
      "\n",
      "-\n",
      "Input sentence: who did you come with\n",
      "Decoded sentence: who went youre for me\n",
      "\n",
      "Quantized Decoded sentence: whw wey kneve you lote\n",
      "\n",
      "-\n",
      "Input sentence: who did you talk with\n",
      "Decoded sentence: who wene your my home\n",
      "\n",
      "Quantized Decoded sentence: whw wey kneve you lote\n",
      "\n",
      "-\n",
      "Input sentence: who do you think i am\n",
      "Decoded sentence: who int youre me mar\n",
      "\n",
      "Quantized Decoded sentence: whw you knvek you low\n",
      "\n",
      "-\n",
      "Input sentence: who else is out there\n",
      "Decoded sentence: why is on your marery\n",
      "\n",
      "Quantized Decoded sentence: whw there your same to ma\n",
      "BLEU Score =  0.981\n",
      "Cosine Score =  0.2112\n",
      "Jaccard Score =  0.4389\n",
      "Levenshtein Score =  15.14\n"
     ]
    }
   ],
   "source": [
    "## VALIDATION TESTING\n",
    "\n",
    "start = int(NUM_SAMPLES * 0.9) + 100\n",
    "samples = 100\n",
    "\n",
    "bleu_val = 0\n",
    "cosine_val = 0\n",
    "jaccard_val = 0\n",
    "levenshtein_val = 0\n",
    "\n",
    "cosine = Cosine(1)\n",
    "jaccard = Jaccard(1)\n",
    "levenshtein = Levenshtein()\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "for seq_index in range(start, start + samples):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    decoded_sentence_quant = decode_sequence(input_seq, quant = True)\n",
    "    \n",
    "    cosine_val += cosine.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    jaccard_val += jaccard.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    levenshtein_val += levenshtein.distance(input_texts[seq_index], decoded_sentence_quant)\n",
    "    bleu_val += bleu([input_texts[seq_index].split()], decoded_sentence_quant.split(), smoothing_function = smoothie)    \n",
    "    \n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('Quantized Decoded sentence:', decoded_sentence_quant)\n",
    "    \n",
    "print(\"BLEU Score = \", round(1. - (bleu_val / samples), 4))\n",
    "print(\"Cosine Score = \", round(cosine_val / samples, 4))\n",
    "print(\"Jaccard Score = \", round(jaccard_val / samples, 4))\n",
    "print(\"Levenshtein Score = \", round(levenshtein_val / samples, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
